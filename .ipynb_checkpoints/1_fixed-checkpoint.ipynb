{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e99b509",
   "metadata": {},
   "source": [
    "# ðŸ§¹ Cleaned Customer Churn Prediction Notebook\n",
    "\n",
    "**What I did:**\n",
    "- Removed fragile / outdated imports and non-functional cells.\n",
    "- Consolidated the pipeline: load data â†’ preprocess â†’ train/test split â†’ model â†’ eval â†’ save model.\n",
    "\n",
    "**Notes for you:**\n",
    "- Put your dataset as `churn.csv` in the same folder, or modify the path in the data-loading cell.\n",
    "- If you want specific parts restored from your original notebook, tell me which cell numbers or paste the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83658ce1",
   "metadata": {},
   "source": [
    "## 1) Environment / Requirements\n",
    "\n",
    "Run this cell to ensure required packages are installed in the environment (you may need to run it once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ba0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Uncomment and run if packages are missing in your environment\n",
    "# !pip install pandas scikit-learn matplotlib seaborn joblib openpyxl\n",
    "print('Assuming standard data-science packages are installed: pandas, scikit-learn, matplotlib, seaborn, joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e98abf",
   "metadata": {},
   "source": [
    "## 2) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95587ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "print('Imports successful')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620cb4d0",
   "metadata": {},
   "source": [
    "## 3) Load dataset (robust)\n",
    "\n",
    "Looks for `churn.csv`. If not found, creates a small synthetic dataset so the notebook runs end-to-end for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f37157",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'churn.csv'\n",
    "\n",
    "if os.path.exists(DATA_PATH):\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f'Loaded dataset from {DATA_PATH} â€” rows: {len(df):,}, columns: {len(df.columns):,}')\n",
    "else:\n",
    "    print(f'File {DATA_PATH} not found. Creating a small synthetic dataset for demo purposes.')\n",
    "    rng = np.random.RandomState(0)\n",
    "    n = 500\n",
    "    df = pd.DataFrame({\n",
    "        'age': rng.randint(18,80,size=n),\n",
    "        'tenure_months': rng.randint(0,72,size=n),\n",
    "        'monthly_charges': np.round(rng.uniform(20,120,size=n),2),\n",
    "        'has_partner': rng.choice(['Yes','No'], size=n),\n",
    "        'contract_type': rng.choice(['Month-to-month','One year','Two year'], size=n),\n",
    "        'churn': rng.choice([0,1], size=n, p=[0.75,0.25])\n",
    "    })\n",
    "\n",
    "# Quick peek\n",
    "print(df.head())\n",
    "print('\\nData shape:', df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9eb62d",
   "metadata": {},
   "source": [
    "## 4) Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4581bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "print(df.info())\n",
    "\n",
    "# Numeric summary\n",
    "print('\\nNumeric summary:')\n",
    "print(df.select_dtypes(include=[np.number]).describe().T)\n",
    "\n",
    "# Class balance\n",
    "print('\\nChurn distribution:')\n",
    "print(df['churn'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378df3d6",
   "metadata": {},
   "source": [
    "## 5) Preprocessing and feature setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features\n",
    "TARGET = 'churn'\n",
    "features = [c for c in df.columns if c != TARGET]\n",
    "\n",
    "# Simple heuristic: categorical = object or category dtype\n",
    "categorical_features = [c for c in features if df[c].dtype == 'object' or df[c].dtype.name == 'category']\n",
    "numeric_features = [c for c in features if c not in categorical_features]\n",
    "\n",
    "print('Numeric features:', numeric_features)\n",
    "print('Categorical features:', categorical_features)\n",
    "\n",
    "# Preprocessing transformers\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f3afa",
   "metadata": {},
   "source": [
    "## 6) Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd219a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8a5eb",
   "metadata": {},
   "source": [
    "## 7) Model pipeline and training\n",
    "\n",
    "Using RandomForest for a robust baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Model trained')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47f290",
   "metadata": {},
   "source": [
    "## 8) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce709f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_proba = None\n",
    "if hasattr(model, 'predict_proba'):\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test)[:,1]\n",
    "    except Exception:\n",
    "        y_proba = None\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "if y_proba is not None:\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    print(f'ROC AUC: {roc:.4f}')\n",
    "    RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Probability estimates not available â€” skipping ROC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1065fe5",
   "metadata": {},
   "source": [
    "## 9) Feature importance (approximate)\n",
    "\n",
    "This shows feature importance if the classifier exposes feature_importances_. For pipeline with OneHotEncoder, we reconstruct feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7bb3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clf = model.named_steps['classifier']\n",
    "    pre = model.named_steps['preprocessor']\n",
    "    # Get transformed feature names for numeric + onehot\n",
    "    num_feats = numeric_features\n",
    "    cat_feats = []\n",
    "    if 'cat' in pre.named_transformers_:\n",
    "        ohe = pre.named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_names = ohe.get_feature_names_out(categorical_features)\n",
    "        cat_feats = list(cat_names)\n",
    "    feature_names = list(num_feats) + cat_feats\n",
    "    importances = clf.feature_importances_\n",
    "    fi = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "    print(fi.head(20))\n",
    "except Exception as e:\n",
    "    print('Could not compute feature importances:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c8515",
   "metadata": {},
   "source": [
    "## 10) Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_MODEL = 'churn_model.joblib'\n",
    "try:\n",
    "    joblib.dump(model, OUT_MODEL)\n",
    "    print(f'Model saved to {OUT_MODEL}')\n",
    "except Exception as e:\n",
    "    print('Error saving model:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e47f9e",
   "metadata": {},
   "source": [
    "## 11) Example: load saved model and predict on a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576085c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and run a single prediction\n",
    "m = joblib.load(OUT_MODEL)\n",
    "print('Loaded model from', OUT_MODEL)\n",
    "\n",
    "sample = X_test.iloc[:3]\n",
    "print('Sample input:\\n', sample)\n",
    "print('Predictions:', m.predict(sample))\n",
    "if hasattr(m, 'predict_proba'):\n",
    "    print('Probabilities:', m.predict_proba(sample)[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c34d3",
   "metadata": {},
   "source": [
    "## 12) Next steps / suggestions\n",
    "\n",
    "- Replace the synthetic demo data with your real `churn.csv` file.\n",
    "- Add cross-validation, hyperparameter tuning (GridSearchCV / RandomizedSearchCV).\n",
    "- Add better EDA plots and missing-value handling depending on your data.\n",
    "- If you want me to restore or port specific cells from your original notebook, tell me the cell numbers or paste code snippets."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
